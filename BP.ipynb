{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ç†è§£BPç®—æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ç›´è§‰å‘Šè¯‰æˆ‘ä»¬ï¼š  \n",
    "åŒä¸€å±‚ä¸­æƒé‡è¾ƒå¤§çš„è¿æ¥åœ¨åå‘ä¼ æ’­è¯¯å·®æ—¶åˆ†æ‹…äº†æ›´å¤šçš„è¯¯å·®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![fanxiang](images/åå‘ä¼ æ’­è¯¯å·®.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "å¯¹äºå¤æ‚çš„éçº¿æ€§é—®é¢˜ï¼ˆåŒ…å«æ¿€æ´»å‡½æ•°ï¼‰ï¼Œæƒ³è¦è®©è¯¯å·®æœ€å°/å¾—åˆ°æŸå¤±å‡½æ•°æœ€å°å€¼ï¼Œ\n",
    "**æ¢¯åº¦ä¸‹é™æ³•**æ˜¯ä¸€ç§å¾ˆå¥½çš„æ–¹æ³•\n",
    "- ä¼˜ç‚¹ï¼š\n",
    "    - æ–¹æ³•æœ¬èº«ç®€å•ï¼Œè¦æ±‚ä½\n",
    "    - æ–¹æ³•å…·æœ‰å¼¹æ€§ï¼Œèƒ½å¤Ÿå®¹å¿ä¸å®Œå–„æ•°æ®\n",
    "- ç¼ºç‚¹ï¼š\n",
    "    - æ•´ä½“æ”¶æ•›é€Ÿåº¦ä¸ä¸€å®šæœ€å¿«"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "å¯¹äºä¸€ä¸ªæŸå¤±å‡½æ•°ä¸º**å¹³æ–¹è¯¯å·®å‡½æ•°**ï¼Œæ¿€æ´»å‡½æ•°ä¸º**Sigmoidå‡½æ•°**çš„å•éšå±‚ç¥ç»ç½‘ç»œã€‚\n",
    " \n",
    "å…¶éšè—å±‚ä¸è¾“å‡ºå±‚æƒé‡çš„æ›´æ–°å€¼ä¸ºï¼š$\\frac{\\partial E}{\\partial W_{j,k}} = -(t_k-o_k) \\cdot o_k \\cdot (1-o_k) \\cdot o_j$  \n",
    "å…¶è¾“å…¥å±‚ä¸éšè—å±‚æƒé‡çš„æ›´æ–°å€¼ä¸ºï¼š$\\frac{\\partial E}{\\partial W_{i,j}} = - e_j \\cdot o_j \\cdot (1-o_j) \\cdot o_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ä½¿ç”¨å•éšå±‚ç¥ç»ç½‘ç»œå®Œæˆæ‰‹å†™æ•°å­—è¯†åˆ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.special\n",
    "\n",
    "class neuralNetwork:\n",
    "    # å®šä¹‰ç¥ç»ç½‘ç»œ\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # w11 w21\n",
    "        # w12 w22\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # sigmoid\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # å°†è¾“å…¥è½¬æ¢ä¸ºäºŒç»´\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        \n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        \n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # è¾“å‡ºå±‚è¯¯å·®ä¸º target - è¾“å‡º\n",
    "        output_errors = targets - final_outputs\n",
    "        # éšå±‚è¯¯å·®ä¸º éšå±‚è¾“å‡ºå±‚æƒé‡*è¾“å‡ºå±‚è¯¯å·®\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # æ›´æ–°ä¸¤å±‚æƒé‡ï¼Œæ ¹æ®å…¬å¼\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "\n",
    "    \n",
    "    def query(self, inputs_list):\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–èŠ‚ç‚¹æ•°é‡å’Œå­¦ä¹ ç‡\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# åŠ è½½æ•°æ®é›†å’Œæµ‹è¯•é›†\n",
    "with open(\"mnist_train.csv\", 'r')as f:\n",
    "    training_data_list = f.readlines()\n",
    "with open(\"mnist_test.csv\", 'r') as f2:\n",
    "    test_data_list = f2.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    for record in training_data_list:\n",
    "        all_values = record.split(',')\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# è®¡ç®—å‡†ç¡®ç‡ï¼Œä½¿ç”¨å¾—åˆ†æ¿\n",
    "scorecard = []\n",
    "for record in test_data_list:\n",
    "    all_values = record.split(',')\n",
    "    correct_label = int(all_values[0])\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    outputs = n.query(inputs)\n",
    "    label = numpy.argmax(outputs)\n",
    "    if (label == correct_label):\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        scorecard.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance = 0.9766\n"
     ]
    }
   ],
   "source": [
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (f\"performance = {scorecard_array.sum() / scorecard_array.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# è‡ªåŠ¨æ±‚å¯¼\n",
    "- è‡ªåŠ¨æ±‚å¯¼è®¡ç®—ä¸€ä¸ªå‡½æ•°åœ¨æŒ‡å®šå€¼ä¸Šçš„å¯¼æ•°\n",
    "- ä¸ç¬¦å·æ±‚å¯¼ã€æ•°å€¼æ±‚å¯¼ä¸åŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- ç¬¦å·æ±‚å¯¼\n",
    "![fuhao](images/ç¬¦å·æ±‚å¯¼.png)\n",
    "- æ•°å€¼æ±‚å¯¼\n",
    "![shuzhi](images/æ•°å€¼æ±‚å¯¼.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# è®¡ç®—å›¾\n",
    "- å°†å…¬å¼åˆ†è§£æˆæœ€å°æ“ä½œï¼ˆå…ƒæ“ä½œã€æ“ä½œå­ï¼‰\n",
    "- å°†è®¡ç®—è¡¨ç¤ºæˆä¸€ä¸ªæ— ç¯å›¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![DAG](images/æ— ç¯å›¾.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- é“¾å¼æ³•åˆ™: $\\frac{\\partial y}{\\partial x}=\\frac{\\partial y}{\\partial u_n} \\frac{\\partial u_n}{\\partial u_{n-1}} \\ldots \\frac{\\partial u_2}{\\partial u_1} \\frac{\\partial u_1}{\\partial x}$\n",
    "-æ­£å‘ç´¯ç§¯ $$\\frac{\\partial y}{\\partial x}=\\frac{\\partial y}{\\partial u_n}\\left(\\frac{\\partial u_n}{\\partial u_{n-1}}\\left(\\ldots\\left(\\frac{\\partial u_2}{\\partial u_1} \\frac{\\partial u_1}{\\partial x}\\right)\\right)\\right)$$\n",
    "-åå‘ç´¯ç§¯ã€åˆç§°åå‘ä¼ é€’\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial x}=\\left(\\left(\\left(\\frac{\\partial y}{\\partial u_n} \\frac{\\partial u_n}{\\partial u_{n-1}}\\right) \\ldots\\right) \\frac{\\partial u_2}{\\partial u_1}\\right) \\frac{\\partial u_1}{\\partial x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### è®¡ç®—å•ä¸ªå˜é‡æ¢¯åº¦çš„å¤æ‚åº¦\n",
    "- æ—¶é—´å¤æ‚åº¦\n",
    "    - æ­£å‘åå‘å‡ä¸º$O(n)$\n",
    "- ç©ºé—´å¤æ‚åº¦\n",
    "    - æ­£å‘$O(1)$\n",
    "    - åå‘$O(n)$ç”¨äºå­˜å‚¨æ­£å‘è®¡ç®—çš„å…¨éƒ¨ç»“æœï¼Œ**éœ€è¦è®¡ç®—å¤šä¸ªå˜é‡çš„æ¢¯åº¦æ—¶æ•ˆæœæ›´ä¼˜**ğŸŒŸ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ä½¿ç”¨pytorchè‡ªåŠ¨æ±‚å¯¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MNISTDataSet(Dataset):\n",
    "    def __init__(self,path):\n",
    "        with open(path,'r') as f:\n",
    "            csv = pd.read_csv(path,header=None)\n",
    "        targets = csv.values[:,0]\n",
    "        self.features = csv.values[:,1:]/255.0*0.99 + 0.01\n",
    "\n",
    "        self.labels = numpy.zeros((targets.shape[0],10)) + 0.01\n",
    "        for i in range(len(targets)):\n",
    "            self.labels[i,int(targets[i])] = 0.99\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.labels[idx],self.features[idx]\n",
    "        \n",
    "train_set = MNISTDataSet('mnist_train.csv')\n",
    "test_set = MNISTDataSet('mnist_test.csv')\n",
    "train_loader = DataLoader(train_set,batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(test_set,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "class SingleHiddenNerualNetwork(nn.Module):\n",
    "    def __init__(self,input_num,hidden_num,output_num):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=input_num,out_features=hidden_num,bias=True)\n",
    "        self.layer2 = nn.Linear(in_features=hidden_num,out_features=output_num,bias=True)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        x = torch.sigmoid(self.layer2(torch.sigmoid(self.layer1(x))))\n",
    "        y = torch.argmax(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "net = SingleHiddenNerualNetwork(784,200,10)\n",
    "net = net.double()\n",
    "net.apply(weights_init)\n",
    "\n",
    "epochs = 200\n",
    "lr = 0.1\n",
    "loss = nn.MSELoss()\n",
    "updater = torch.optim.SGD(net.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 loss:0.08034828241029349\n",
      "epoch1 loss:0.07670363993730017\n",
      "epoch2 loss:0.067474609922055\n",
      "epoch3 loss:0.06000419883749577\n",
      "epoch4 loss:0.04718294404907688\n",
      "epoch5 loss:0.03745918295145245\n",
      "epoch6 loss:0.0393590795468021\n",
      "epoch7 loss:0.03784484748513417\n",
      "epoch8 loss:0.041346607476078864\n",
      "epoch9 loss:0.030116500240849952\n",
      "epoch10 loss:0.028333975697377056\n",
      "epoch11 loss:0.025343488888708687\n",
      "epoch12 loss:0.022716151022046455\n",
      "epoch13 loss:0.02659029279208825\n",
      "epoch14 loss:0.035229157848461236\n",
      "epoch15 loss:0.030771429809598388\n",
      "epoch16 loss:0.022124340451695833\n",
      "epoch17 loss:0.018623662176440965\n",
      "epoch18 loss:0.02282241545428494\n",
      "epoch19 loss:0.027965213975814186\n",
      "epoch20 loss:0.03331219396558747\n",
      "epoch21 loss:0.03331885266981581\n",
      "epoch22 loss:0.03032288276695269\n",
      "epoch23 loss:0.023403952431129773\n",
      "epoch24 loss:0.019845140228108328\n",
      "epoch25 loss:0.01556962601845606\n",
      "epoch26 loss:0.021563081489569293\n",
      "epoch27 loss:0.024676564378801686\n",
      "epoch28 loss:0.023322325628249742\n",
      "epoch29 loss:0.017192547031382586\n",
      "epoch30 loss:0.02009533271536083\n",
      "epoch31 loss:0.01977679745358478\n",
      "epoch32 loss:0.020692436350981634\n",
      "epoch33 loss:0.015096958043233206\n",
      "epoch34 loss:0.02103697720091536\n",
      "epoch35 loss:0.015490085135462345\n",
      "epoch36 loss:0.023981016044668655\n",
      "epoch37 loss:0.024010951928532788\n",
      "epoch38 loss:0.027594991604223018\n",
      "epoch39 loss:0.02736569630445726\n",
      "epoch40 loss:0.011280586818377493\n",
      "epoch41 loss:0.022456403659320424\n",
      "epoch42 loss:0.01565264434154439\n",
      "epoch43 loss:0.021982904226375347\n",
      "epoch44 loss:0.010922058622196303\n",
      "epoch45 loss:0.023013070638369625\n",
      "epoch46 loss:0.021985205807800275\n",
      "epoch47 loss:0.012477844829521006\n",
      "epoch48 loss:0.012278432167839373\n",
      "epoch49 loss:0.020759895040547198\n",
      "epoch50 loss:0.02548638361043254\n",
      "epoch51 loss:0.022838427736621945\n",
      "epoch52 loss:0.019045916376398114\n",
      "epoch53 loss:0.016575743205668382\n",
      "epoch54 loss:0.01506744065271352\n",
      "epoch55 loss:0.02036025979026145\n",
      "epoch56 loss:0.014929430500395913\n",
      "epoch57 loss:0.01418370991388727\n",
      "epoch58 loss:0.013352853191530867\n",
      "epoch59 loss:0.016310882613314148\n",
      "epoch60 loss:0.020344534281571104\n",
      "epoch61 loss:0.01215868038454752\n",
      "epoch62 loss:0.006174299217747753\n",
      "epoch63 loss:0.019268353878722007\n",
      "epoch64 loss:0.01114682755859536\n",
      "epoch65 loss:0.014029049894527277\n",
      "epoch66 loss:0.019137289668591413\n",
      "epoch67 loss:0.0194062592352361\n",
      "epoch68 loss:0.01782157617590326\n",
      "epoch69 loss:0.01780855280165039\n",
      "epoch70 loss:0.01705105801708815\n",
      "epoch71 loss:0.01923885421023868\n",
      "epoch72 loss:0.011208921727038917\n",
      "epoch73 loss:0.015817113117652888\n",
      "epoch74 loss:0.007804444269711228\n",
      "epoch75 loss:0.018153706533032637\n",
      "epoch76 loss:0.013111384802057393\n",
      "epoch77 loss:0.015216850708573915\n",
      "epoch78 loss:0.011037742369815418\n",
      "epoch79 loss:0.01802125443801964\n",
      "epoch80 loss:0.013779779660976632\n",
      "epoch81 loss:0.007646403477207062\n",
      "epoch82 loss:0.011705401720456301\n",
      "epoch83 loss:0.006392569323288409\n",
      "epoch84 loss:0.014501065862425836\n",
      "epoch85 loss:0.015414552513362361\n",
      "epoch86 loss:0.028247875599164807\n",
      "epoch87 loss:0.010438847344833288\n",
      "epoch88 loss:0.02333366611488607\n",
      "epoch89 loss:0.012086630476927086\n",
      "epoch90 loss:0.01592456396647628\n",
      "epoch91 loss:0.010538924781211776\n",
      "epoch92 loss:0.012036842848520982\n",
      "epoch93 loss:0.01619159648379408\n",
      "epoch94 loss:0.024329448855756018\n",
      "epoch95 loss:0.014827439869332184\n",
      "epoch96 loss:0.022769363146696996\n",
      "epoch97 loss:0.019175068154022267\n",
      "epoch98 loss:0.008637068978858587\n",
      "epoch99 loss:0.02510780921662681\n",
      "epoch100 loss:0.018974989929637497\n",
      "epoch101 loss:0.009003778949472952\n",
      "epoch102 loss:0.017458321222163863\n",
      "epoch103 loss:0.021306505775195\n",
      "epoch104 loss:0.008615042578422598\n",
      "epoch105 loss:0.016141091508318665\n",
      "epoch106 loss:0.01648998363218689\n",
      "epoch107 loss:0.007748567957388433\n",
      "epoch108 loss:0.024350964219532895\n",
      "epoch109 loss:0.01757658742706796\n",
      "epoch110 loss:0.01169560613610669\n",
      "epoch111 loss:0.018542145589352698\n",
      "epoch112 loss:0.007218503439346094\n",
      "epoch113 loss:0.005557984241511933\n",
      "epoch114 loss:0.0069562651700739025\n",
      "epoch115 loss:0.006769320955196835\n",
      "epoch116 loss:0.016172220121327116\n",
      "epoch117 loss:0.010660544801597813\n",
      "epoch118 loss:0.01413976065738554\n",
      "epoch119 loss:0.013237223020185433\n",
      "epoch120 loss:0.02374323968948606\n",
      "epoch121 loss:0.004486714347551833\n",
      "epoch122 loss:0.013748062192340826\n",
      "epoch123 loss:0.017583100964719135\n",
      "epoch124 loss:0.018652427420563836\n",
      "epoch125 loss:0.02000311053104278\n",
      "epoch126 loss:0.02746198858452716\n",
      "epoch127 loss:0.020074985163903363\n",
      "epoch128 loss:0.01715284988501259\n",
      "epoch129 loss:0.013027401328900049\n",
      "epoch130 loss:0.012242424043193128\n",
      "epoch131 loss:0.006443531905563647\n",
      "epoch132 loss:0.008721504549893237\n",
      "epoch133 loss:0.017014310282547594\n",
      "epoch134 loss:0.019030082452576754\n",
      "epoch135 loss:0.019769872086580827\n",
      "epoch136 loss:0.006773715337320641\n",
      "epoch137 loss:0.011911887706466447\n",
      "epoch138 loss:0.007920627103168099\n",
      "epoch139 loss:0.01080249131812656\n",
      "epoch140 loss:0.015832671051235765\n",
      "epoch141 loss:0.014635879402946897\n",
      "epoch142 loss:0.004609339039840168\n",
      "epoch143 loss:0.005873528236522836\n",
      "epoch144 loss:0.01668900251469322\n",
      "epoch145 loss:0.014039357632768637\n",
      "epoch146 loss:0.008950350073525338\n",
      "epoch147 loss:0.019137986699989628\n",
      "epoch148 loss:0.010898651448096446\n",
      "epoch149 loss:0.013280967173804031\n",
      "epoch150 loss:0.011647435966438614\n",
      "epoch151 loss:0.007378690828872223\n",
      "epoch152 loss:0.004030153952346611\n",
      "epoch153 loss:0.009205510309771979\n",
      "epoch154 loss:0.008399488883698368\n",
      "epoch155 loss:0.012916776118484755\n",
      "epoch156 loss:0.012428156189469422\n",
      "epoch157 loss:0.011955073800699281\n",
      "epoch158 loss:0.01138902997560312\n",
      "epoch159 loss:0.013537494264849997\n",
      "epoch160 loss:0.005826565776356203\n",
      "epoch161 loss:0.006563146736248619\n",
      "epoch162 loss:0.021112813939632567\n",
      "epoch163 loss:0.01516129620585126\n",
      "epoch164 loss:0.021268468919003074\n",
      "epoch165 loss:0.01900467024288282\n",
      "epoch166 loss:0.005833242248690053\n",
      "epoch167 loss:0.017642543139864634\n",
      "epoch168 loss:0.011690478808460955\n",
      "epoch169 loss:0.010304502508508413\n",
      "epoch170 loss:0.010608415257340163\n",
      "epoch171 loss:0.01376715313226351\n",
      "epoch172 loss:0.020413906640042306\n",
      "epoch173 loss:0.01635564309261505\n",
      "epoch174 loss:0.010354542183380017\n",
      "epoch175 loss:0.01941854367183813\n",
      "epoch176 loss:0.015445816048732219\n",
      "epoch177 loss:0.011475439236370856\n",
      "epoch178 loss:0.0041884273573173595\n",
      "epoch179 loss:0.009788277032208375\n",
      "epoch180 loss:0.01340346092817703\n",
      "epoch181 loss:0.008918253562239188\n",
      "epoch182 loss:0.01687966218013205\n",
      "epoch183 loss:0.015862684151457456\n",
      "epoch184 loss:0.010659174821829088\n",
      "epoch185 loss:0.01652205167049118\n",
      "epoch186 loss:0.020323125478753944\n",
      "epoch187 loss:0.021822008850025422\n",
      "epoch188 loss:0.011770013419355218\n",
      "epoch189 loss:0.02129347938708855\n",
      "epoch190 loss:0.016250661605836905\n",
      "epoch191 loss:0.006751858688545084\n",
      "epoch192 loss:0.01197079702411508\n",
      "epoch193 loss:0.02296672108987924\n",
      "epoch194 loss:0.008867225282910205\n",
      "epoch195 loss:0.015917640315128274\n",
      "epoch196 loss:0.01032678629281052\n",
      "epoch197 loss:0.011765246672609139\n",
      "epoch198 loss:0.005577620071182993\n",
      "epoch199 loss:0.016134027981450548\n",
      "cost time:245.71074295043945\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "# è®­ç»ƒå¼€å§‹\n",
    "for i in range(epochs):\n",
    "    for y,x in iter(train_loader):\n",
    "        y_hat = net(x)\n",
    "        l = loss(y_hat,y)\n",
    "        updater.zero_grad()\n",
    "        l.sum().backward()\n",
    "        updater.step()\n",
    "    print(f'epoch{i} loss:{l}')\n",
    "\n",
    "end = time.time()\n",
    "print(f'cost time:{end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9345\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥æµ‹è¯•é›†å‡†ç¡®ç‡\n",
    "net.eval()\n",
    "metric = [0,0]\n",
    "for test_labels,test_features in iter(test_loader):\n",
    "    test_labels = torch.argmax(test_labels)\n",
    "    label_pre = net.predict(test_features)\n",
    "#     print(label_pre.shape,label_pre)\n",
    "    if label_pre == test_labels:\n",
    "        metric[0]+=1        \n",
    "    metric[1]+=1\n",
    "print(f'acc:{metric[0]/metric[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# å°ç»“\n",
    "- å±€éƒ¨æœ€å°ç‚¹\n",
    "- æ¢¯åº¦ä¸‹é™æ…¢ã€èµ„æºå ç”¨é«˜\n",
    "- æ¿€æ´»å‡½æ•°çµæ´»"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "å¹»ç¯ç‰‡",
  "kernelspec": {
   "display_name": "Python [conda env:dl] *",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
